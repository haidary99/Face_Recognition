{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this version, I'm trying to see if I can confirm if an employee is present only if he is showing in the frames (video feed) for about 3 seconds to make it more robust."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=IT53xBR1A7M&list=PLqUHmcsDDjLjFSo4iumsXGhQoaNu-aXUF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook is used to detect faces in images (using MTCNN) stored in `photos` directory and extract their features (using InceptionResnetV1) and store them in `data.pt` file. This file is then loaded later in order to extract the features of faces stored in it and compare it with the face(s) detected in each live frame from a camera stream. If there is a match according to some threshold, then it will label the person in the frame.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing MTCNN and InceptionResnetv1\n",
    "\n",
    "mtcnn0 = MTCNN(image_size=240, margin=0, keep_all=False, min_face_size=40) # keep_all = False means if one img contains many faces then it will keep only 1 face of those\n",
    "mtcnn = MTCNN(image_size=240, margin=0, keep_all=True, min_face_size=300) # keep_all = True keeps all faces in a form of list, Also changed mmin_face_size to 150 to ignore small faces in frame which might be difficult to classify\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval() # creating an instance of pre-trained InceptionResnetV1 model trained on the VGGFace2 dataset to extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Loei_Haidari', 1: 'Najwa', 2: 'Taher_Haidari', 3: 'Yousef_Haidari'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from directory\n",
    "\n",
    "dataset = datasets.ImageFolder('photos') # photos directory path\n",
    "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # new dictionary of indecis and class names\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x154500160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = [] # list of names corresponding to cropped photos\n",
    "embedding_list = [] # list of embedding matrix after conversion from cropped faces to embedding matrix using resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, idx in loader: # img is in PIL format, here we are looping thru the images in the photos directory (loader)\n",
    "    face, prob = mtcnn0(img, return_prob=True) # img passed into mtcnn0, face is the cropped face (note: in mtcnn0 it will return only ONE face)\n",
    "    if face is not None and prob>0.92: # if face is not None means that there's a face that exists \n",
    "        emb = resnet(face.unsqueeze(0)) # pass the face into resnet, unsqueeze b/c resnet expects 4 dimensions (dimension of batch included). Result of this is an embedding\n",
    "        embedding_list.append(emb.detach()) # .detach() to make requires_grad false\n",
    "        name_list.append(idx_to_class[idx])\n",
    "\n",
    "# save data\n",
    "data = [embedding_list, name_list] # make a new list of the previous 2 lists\n",
    "torch.save(data, 'data.pt') # saving to make this code reusable without having to go thru the previous loops and steps every single time which is very costly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using webcam to recognize the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n",
      "Yousef Haidari detected in 30 subsequent frames!\n"
     ]
    }
   ],
   "source": [
    "# Loading data.pt file\n",
    "load_data = torch.load('data.pt')\n",
    "embedding_list = load_data[0] \n",
    "name_list = load_data[1]\n",
    "\n",
    "cam = cv2.VideoCapture(0) # initializing the camera from CV, 0 means the default webcam in the device\n",
    "\n",
    "person_to_track = \"Yousef Haidari\"\n",
    "consecutive_frames = 0\n",
    "\n",
    "while True: # read all the frames in the video\n",
    "    ret, frame = cam.read() # return is true or false, if the webcam succesfully captures an image then it is true otherwise false. frame reperesnts a single frame (image) captured from the webcam using VideoCapture object\n",
    "    if not ret:\n",
    "        print(\"Fail to grab frame, try again\")\n",
    "        break\n",
    "    \n",
    "    img = Image.fromarray(frame) # Image class is part of PIL, .fromarray() is a method that creates an \"Image\" object from a numpy array \n",
    "    img_cropped_list, prob_list = mtcnn(img, return_prob=True) # pass the image into mtcnn, mtcnn will return multiple faces if the image contain multiple faces, also return all the probabilities for all the faces\n",
    "\n",
    "    if img_cropped_list is not None: # if the image has at least one face\n",
    "        boxes, _ = mtcnn.detect(img) # return the boxes of faces \n",
    "        # print(boxes[0][0])\n",
    "\n",
    "        for i, prob in enumerate(prob_list): # loop thru the prob list\n",
    "            if prob > 0.90: \n",
    "                emb = resnet(img_cropped_list[i].unsqueeze(0)).detach()\n",
    "                \n",
    "                dist_list = [] # for the distance between the current embedding and embeddings of faces in the photos directory (similarity). Minimum distance is used to identify the person\n",
    "\n",
    "                for idx, emd_db in enumerate(embedding_list):\n",
    "                    dist = torch.dist(emb, emd_db).item() # calc. distance betweem current embedding and embeddings stored embedding_list\n",
    "                    dist_list.append(dist)\n",
    "\n",
    "                # print(f\"Minimum distance array:\\n{dist_list}\")\n",
    "                min_dist = min(dist_list) # get minimum dist value\n",
    "                formatted_min_dist = f'{min_dist:.4f}' # used for printing on the frame\n",
    "                min_dist_idx = dist_list.index(min_dist) # get minimum dist index (where the min dist is located in the array)\n",
    "                name = name_list[min_dist_idx] # get name corresponding to minium dist ##########\n",
    "                name = name.replace('_', ' ')\n",
    "\n",
    "                box = boxes[i]\n",
    " \n",
    "                if name == person_to_track:\n",
    "                    consecutive_frames += 1\n",
    "                else:\n",
    "                    consecutive_frames = 0\n",
    "                \n",
    "                if consecutive_frames >= 45:\n",
    "                    print(f\"{person_to_track} detected in 30 subsequent frames!\")\n",
    "\n",
    "                original_frame = frame.copy() # storing a copy of frame before drawing on it\n",
    "        \n",
    "                if min_dist<0.90:\n",
    "                    frame = cv2.putText(frame, name+' '+str(formatted_min_dist), (int(box[0])-5, int(box[1])-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                frame = cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255,0,0), 3)\n",
    "\n",
    "    cv2.imshow(\"IMG\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    # Press q or esc to quit, space bar to add & save new image\n",
    "    if k == ord('q'):\n",
    "        break # Quit the program\n",
    "\n",
    "    elif k == 27: # 27 is for esc key\n",
    "        break\n",
    "\n",
    "    elif k == 32: # 32 is the ASCII of space bar\n",
    "        print('Enter your name: ')\n",
    "        name = input()\n",
    "        if name == \"\": ###### I ADDED THESE 2 LINES IN CASE INPUT WAS EMPTY IT DOESN'T SAVE TEH IMAGE\n",
    "            continue\n",
    "\n",
    "        # Create directory if class/person does not exist in photos directory\n",
    "        if not os.path.exists('photos/'+name):\n",
    "            os.mkdir('photos/'+name)\n",
    "\n",
    "        img_name = f\"photos/{name}/{int(time.time())}.jpg\"\n",
    "        cv2.imwrite(img_name, original_frame)\n",
    "        print(f\"saved: {img_name}\")\n",
    "\n",
    "cam.release()\n",
    "\n",
    "for i in range(1):\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# OR the below method, but below method requires one more key press to destroy the window while the above loop automatically closes the window without extra key press\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1) # This is the only extra line u need on top of windows os uses to work properly on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script face_reco.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
